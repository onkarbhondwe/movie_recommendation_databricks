{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc2d07bf-17d9-41fc-814a-76c6805a635d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We already have sc and sqlContext for us here\n",
    "print(sc)\n",
    "print(sqlContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad088c3f-0a10-4718-b02d-f1e4051ab534",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Getting the data\n",
    "It is already mounted for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b3abe4e-636e-4d8b-8174-ef3466b9b232",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We will use these 2 files for our analysis and collabrative filtering\n",
    "ratings_filename = \"dbfs:/mnt/Files/Validated/ratings.csv\"\n",
    "movies_filename =\"dbfs:/mnt/Files/Validated/movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18149f9a-04d1-4371-b946-53c5544f520f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs \n",
    "ls dbfs:/mnt/Files/Validated/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4c7c7a5-8dee-4594-9000-3d912a89c051",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.head(movies_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81bbc940-3c0b-4301-bed2-7406c7bb91ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A Little analysis on the movies.csv\n",
    "We will create 2 dataframes for our analysis which will make the visualization with Databricks display function pretty straightforward- \n",
    "1. movies_based_on_time - We will drop the genres here final schema will be (movie_id,name, Year)\n",
    "2. movies_based_on_genres - Final schema would look like (movie_id,name_with_year,one_genre)\n",
    "\n",
    "From the description at [kaggle](https://www.kaggle.com/grouplens/movielens-20m-dataset) we can see the schema of the files. for the sake of computation we would explicitly mention the schema(Spark can infer it itself but that involves an action which at most cases we want to minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cf2a743-32d8-4451-a072-80763615b387",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "#working only on movies.csv right now\n",
    "movies_with_genres_df_schema = StructType(\n",
    "  [StructField('ID', IntegerType()),\n",
    "   StructField('title', StringType()),\n",
    "   StructField('genres',StringType())]\n",
    "  )\n",
    "\n",
    "movies_df_schema = StructType(\n",
    "  [StructField('ID', IntegerType()),\n",
    "   StructField('title', StringType())]\n",
    "  ) #dropping the genres.Also, we will tranform the df to include the Year later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a0e791-5280-4a6d-a444-41a30f4b10b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Creating the dataframes \n",
    "movies_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True, inferSchema=False).schema(movies_df_schema).load(movies_filename)\n",
    "movies_with_genres_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True, inferSchema=False).schema(movies_with_genres_df_schema).load(movies_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb61adc9-de7d-4eba-9983-315492cfccf8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Inspecting the DataFrames before the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c21fd031-99d6-40a0-a904-fae46315239e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "movies_df.show(4,truncate = False) #we will also use this for Collabrative filtering\n",
    "movies_with_genres_df.show(4,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb1a2c61-1870-4a96-ada5-1900ddaf5cd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#transforming the Dataframes\n",
    "from pyspark.sql.functions import split, regexp_extract\n",
    "\n",
    "movies_with_year_df = movies_df.select('ID','title',regexp_extract('title',r'\\((\\d+)\\)',1).alias('year'))\n",
    "\n",
    "#one genre per row\n",
    "movies_with_one_genre_df = sqlContext.createDataFrame(movies_with_genres_df.rdd.map(lambda x: [(x[0],x[1],i) for i in x[2].split('|')])\\\n",
    "    .flatMap(lambda x:x)).toDF('Id','title','one_genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5913346-b3cc-496c-b96b-4e0633698c2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### DataFrames after Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8db6cce0-e718-4f4a-bafe-cf7388f58c44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "movies_with_one_genre_df.show(10,truncate = False)\n",
    "movies_with_year_df.show(4,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d7fbe99-6b40-49da-8cb5-852493186403",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Now we will use the inbuilt functionality of Databricks for some insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d7df93e-a4cc-4925-bd7e-0dd4bfc171ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(movies_with_one_genre_df.groupBy('one_genre').count().sort('count',ascending=False)) #people love drama\n",
    "\n",
    "#Below we have a bar chart here we can choose from a lot of other options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2156ea3a-9cd4-4f05-9e36-d5a957344732",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#from here we can look at the count and find that the maximum number of movies are produced in 2009\n",
    "display(movies_with_year_df.groupBy('year').count().orderBy('count',ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b50779f-c788-49b3-b5c5-838470a8aa73",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "2 Observations from movies.csv\n",
    "1. People love Drama.\n",
    "2. And there are lot of movies each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd8de0c9-929a-44ac-8b02-2947b7d3daf7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Now let's move to Ratings\n",
    "\n",
    "We already have the movie_df now we will require ratings Lets create the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ef597b9-abc8-4008-9282-89f7e5e171f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#again for avoiding the action we are explicitly defining the schema\n",
    "ratings_df_schema = StructType(\n",
    "  [StructField('userId', IntegerType()),\n",
    "   StructField('movieId', IntegerType()),\n",
    "   StructField('rating', DoubleType())]\n",
    ")              #we are dropping the Time Stamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "447fe777-a75e-4a5f-8bb3-0effe534c7dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating the df\n",
    "ratings_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True, inferSchema=False).schema(ratings_df_schema).load(ratings_filename)\n",
    "ratings_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31d85e4b-98f1-487c-a246-e36f7f14bcd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We will cache both the dataframes\n",
    "ratings_df.cache()\n",
    "movies_df.cache()\n",
    "print(\"both dataframes are in cache now for easy accessibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cfabfe0-7192-4578-a81c-78aa642ebd8f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Global Popularity \n",
    "It is good to know the most popular movies,and at times it is very hard to just beat popularity [Xavier Amatriain Lecture](https://www.youtube.com/watch?v=bLhq63ygoU8)\n",
    " Movies with highest average ratings here we will put a constraint on the no. of reviews given we will discard the movies where the count of ratings is less than 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdafe66d-33a4-46f6-93a0-7a3c959b85ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# From ratingsDF, create a movie_ids_with_avg_ratings_df that combines the two DataFrames\n",
    "movie_ids_with_avg_ratings_df = ratings_df.groupBy('movieId').agg(F.count(ratings_df.rating).alias(\"count\"), F.avg(ratings_df.rating).alias(\"average\"))\n",
    "print('movie_ids_with_avg_ratings_df:')\n",
    "movie_ids_with_avg_ratings_df.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10e29a8d-24e1-4a64-a36b-363b4918cb33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#this df will have names with movie_id- Make it more understandable\n",
    "movie_names_with_avg_ratings_df = movie_ids_with_avg_ratings_df.join(movies_df,F.col('movieID') == F.col('ID')).drop('ID')\n",
    "movie_names_with_avg_ratings_df.show(4,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33a10b40-f823-4623-aa22-cb3e388427bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#so let us see the global popularity\n",
    "movies_with_500_ratings_or_more = movie_names_with_avg_ratings_df.filter(movie_names_with_avg_ratings_df['count'] >= 500).orderBy('average',ascending = False)\n",
    "movies_with_500_ratings_or_more.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0955dd2-7468-4683-8a3c-688794ac9ee8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Collaborative filtering now\n",
    "[wikipedia article here](https://en.wikipedia.org/wiki/Collaborative_filtering). We will use the Matrix Factorization algoithm present in spark MLlib called [ALS quora explaination](https://www.quora.com/What-is-the-Alternating-Least-Squares-method-in-recommendation-systems)\n",
    "\n",
    "<img alt=\"factorization\" src=\"http://spark-mooc.github.io/web-assets/images/matrix_factorization.png\" style=\"width: 885px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0dbc625-562f-4158-83c3-e7a1ffe37eff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Splitting in Train, Test and Validation dataset\n",
    "\n",
    "As with all the Machine Learning Algorithms in practice we have to tune parameters and then test accuracy.For this we will split the data into 3 parts Train, Test(Checking the final accuracy) and Validation(optimizing hyperparameters) data. For more information about this [brilliant lecture by Nando](https://www.youtube.com/watch?v=PvuN23m7hhY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "079af5f8-5f1e-45a6-9816-8a3989d8f69a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We'll hold out 60% for training, 20% of our data for validation, and leave 20% for testing\n",
    "seed = 4\n",
    "(split_60_df, split_a_20_df, split_b_20_df) = ratings_df.randomSplit([0.6,0.2,0.2],seed)\n",
    "\n",
    "# Let's cache these datasets for performance\n",
    "training_df = split_60_df.cache()\n",
    "validation_df = split_a_20_df.cache()\n",
    "test_df = split_b_20_df.cache()\n",
    "\n",
    "print('Training: {0}, validation: {1}, test: {2}\\n'.format(\n",
    "  training_df.count(), validation_df.count(), test_df.count())\n",
    ")\n",
    "training_df.show(4,truncate = False)\n",
    "validation_df.show(4,truncate = False)\n",
    "test_df.show(4,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0c63d7b-d12b-44b7-a5bc-aa2f47fd1f60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From above we can see approximately 10 million training samples, 4 million validation and 4 million test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fdf6137-b45b-4baa-a172-60f6d896afe5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Alternating Least Square (ALS)\n",
    "the documentation can be found [here](http://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS)\n",
    "\n",
    "Need of Cross validation, some problems and solutions here I am copying it directly from the Assignment notebook\n",
    "\n",
    "A challenge for collaborative filtering is how to provide ratings to a new user (a user who has not provided *any* ratings at all). Some recommendation systems choose to provide new users with a set of default ratings (e.g., an average value across all ratings), while others choose to provide no ratings for new users. Spark's ALS algorithm yields a NaN (`Not a Number`) value when asked to provide a rating for a new user.\n",
    "\n",
    "Using the ML Pipeline's [CrossValidator](http://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator) with ALS is thus problematic, because cross validation involves dividing the training data into a set of folds (e.g., three sets) and then using those folds for testing and evaluating the parameters during the parameter grid search process. It is likely that some of the folds will contain users that are not in the other folds, and, as a result, ALS produces NaN values for those new users. When the CrossValidator uses the Evaluator (RMSE) to compute an error metric, the RMSE algorithm will return NaN. This will make *all* of the parameters in the parameter grid appear to be equally good (or bad).\n",
    "\n",
    "You can read the discussion on [Spark JIRA 14489](https://issues.apache.org/jira/browse/SPARK-14489) about this issue. There are proposed workarounds of having ALS provide default values or having RMSE drop NaN values. Both introduce potential issues. We have chosen to have RMSE drop NaN values. While this does not solve the underlying issue of ALS not predicting a value for a new user, it does provide some evaluation value. We manually implement the parameter grid search process using a for loop (below) and remove the NaN values before using RMSE.\n",
    "\n",
    "For a production application, you would want to consider the tradeoffs in how to handle new users.\n",
    "\n",
    "I will try to write comments as explicit as possible in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b8ced2e-4aef-493a-98c4-773958462403",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# our ALS learner\n",
    "als = ALS()\n",
    "\n",
    "# Now we set the parameters for the method\n",
    "als.setMaxIter(5)\\\n",
    "   .setSeed(seed)\\\n",
    "   .setRegParam(0.1)\\\n",
    "   .setUserCol('userId')\\\n",
    "   .setItemCol('movieId')\\\n",
    "   .setRatingCol('rating')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e1cb8d5-45cc-4643-aeeb-222325971dd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Now let's compute an evaluation metric for our test and validation dataset\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create an RMSE evaluator using the label and predicted columns\n",
    "#it will essentially calculate the rmse score based on these columns\n",
    "reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"rmse\")\n",
    "\n",
    "tolerance = 0.03\n",
    "\n",
    "#Now to understand rank let us initially assume that my recommendation matrix is 1000 * 1000 (1000 users and 1000 products this is a very sparse matrix)\n",
    "#Now what we do is we get 2 matrices P (shape 1000 * rank) and Q (shape rank * 1000) so essentially now if we multiply them I get the same but now the storage has decreased from storing 1000 * 1000 numbers to 2 * 1000 * rank (for rank = 4 we only need 8000 numbers compared to 1000000)  \n",
    "ranks = [4, 8, 12] \n",
    "errors = [0, 0, 0]\n",
    "models = [0, 0, 0]\n",
    "err = 0\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "for rank in ranks:\n",
    "  # Set the rank here:\n",
    "  als.setRank(rank)\n",
    "  # Create the model with these parameters.\n",
    "  model = als.fit(training_df)\n",
    "  # Run the model to create a prediction. Predict against the validation_df.\n",
    "  predict_df = model.transform(validation_df)\n",
    "\n",
    "  # Remove NaN values from prediction (due to SPARK-14489)\n",
    "  predicted_ratings_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "\n",
    "  # Run the previously created RMSE evaluator, reg_eval, on the predicted_ratings_df DataFrame\n",
    "  error = reg_eval.evaluate(predicted_ratings_df)\n",
    "  errors[err] = error\n",
    "  models[err] = model\n",
    "  print('For rank %s the RMSE is %s' % (rank, error))\n",
    "  if error < min_error:\n",
    "    min_error = error\n",
    "    best_rank = err\n",
    "  err += 1\n",
    "\n",
    "als.setRank(ranks[best_rank])\n",
    "print('The best model was trained with rank %s' % ranks[best_rank])\n",
    "my_model = models[best_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58e1f0d3-19ab-4167-b18b-9c9a65b90cac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Testing our Model\n",
    "\n",
    "Again we will filter out where the prediction is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b540861-4175-4dc5-b771-7e992bbd9e2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# In ML Pipelines, this next step has a bug that produces unwanted NaN values. We\n",
    "# have to filter them out. See https://issues.apache.org/jira/browse/SPARK-14489\n",
    "predict_df = my_model.transform(test_df)\n",
    "\n",
    "# Remove NaN values from prediction (due to SPARK-14489)\n",
    "predicted_test_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_df DataFrame\n",
    "test_RMSE = reg_eval.evaluate(predicted_test_df)\n",
    "\n",
    "print('The model had a RMSE on the test set of {0}'.format(test_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46773c45-1081-4239-893e-fa46a9eed094",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### It is always good to just compare with the by Default model\n",
    "Where we will just get the global average rating for our training dataset and get the RMSE based on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c59d8747-e227-4f96-80e2-3b4ef1b60e5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "default_value = training_df.agg(F.avg('rating')).collect()[0][0]\n",
    "print(default_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b3bf254-ad1e-45bd-a054-9263f7137d24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add a column with the average rating -- getting the RMSE based on a default value (which is same throughout)\n",
    "test_for_avg_df = test_df.withColumn('prediction', F.lit(default_value))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the test_for_avg_df DataFrame\n",
    "test_avg_RMSE = reg_eval.evaluate(test_for_avg_df)\n",
    "\n",
    "print(\"The RMSE on the average set is {0}\".format(test_avg_RMSE)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dab081b0-cc93-47f0-be05-aaaa5fad6536",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Looking at the value we can say we have definitely improved on the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebcc2a67-f008-416b-bd78-aa12a996d13f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Prediction based on our watched Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a69762d4-b670-4ce3-9e1a-ea22ec31cf0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#lets look at the top movies because there would be high chance if I have seen them\n",
    "display(movies_with_500_ratings_or_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21e1904d-bd7a-4d92-91b3-28cee8002274",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let me pick 4 movies and put the ratings in:\n",
    "<pre>\n",
    "My pick                     - my movie_id - my stars\n",
    "Shawshank Redemption          318           5\n",
    "12 angry men                  1203          4\n",
    "Forrest Gump                  356           5\n",
    "GodFather                     858           5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed240202-dede-4c83-8915-70a9024f7f80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Putting the values into Training dataset and training it again\n",
    "As the User id 0 is not used so will use that for the user rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07cc426f-2aea-4e36-9ad2-00600b85cbd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "my_user_id = 0\n",
    "\n",
    "# Note that the movie IDs are the *last* number on each line. A common error was to use the number of ratings as the movie ID.\n",
    "my_rated_movies = [\n",
    "     (0,318,5),(0,1203,4),(0,356,5),(0,858,5)\n",
    "     # The format of each line is (my_user_id, movie ID, your rating)\n",
    "     ]\n",
    "\n",
    "my_ratings_df = sqlContext.createDataFrame(my_rated_movies, ['userId','movieId','rating'])\n",
    "print('My movie ratings:')\n",
    "my_ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9e17463-edc5-417a-bf91-4862c7222023",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Now adding my_ratings to the training_df\n",
    "training_with_my_ratings_df = training_df.unionAll(my_ratings_df)\n",
    "print(\"the train data has %s more entries now\"%(training_with_my_ratings_df.count() - training_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dc91e00-9df6-4a3f-ba53-e7247d94dabd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# Reset the parameters for the ALS object.\n",
    "als.setPredictionCol(\"prediction\")\\\n",
    "   .setMaxIter(5)\\\n",
    "   .setSeed(seed)\\\n",
    "   .setRegParam(0.1)\\\n",
    "   .setUserCol('userId')\\\n",
    "   .setItemCol('movieId')\\\n",
    "   .setRatingCol('rating')\\\n",
    "   .setRank(8)   #we got rank 8 as optimal\n",
    "\n",
    "\n",
    "# Create the model with these parameters.\n",
    "my_ratings_model = als.fit(training_with_my_ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a55fbde0-af17-415d-aeac-0c7d595fca09",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Looking for RMSE again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "121ef1b0-de49-456c-ad74-ecc165811f21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "my_predict_df = my_ratings_model.transform(test_df)\n",
    "\n",
    "# Remove NaN values from prediction\n",
    "predicted_test_my_ratings_df = my_predict_df.filter(my_predict_df.prediction != float('nan'))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_my_ratings_df DataFrame\n",
    "test_RMSE_my_ratings = reg_eval.evaluate(predicted_test_my_ratings_df)\n",
    "print('The model had a RMSE on the test set of {0}'.format(test_RMSE_my_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f9826d7-a30c-4dbe-b091-0e41cb53b98c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Now finding the Movies which best suites me :)\n",
    "\n",
    "Some steps how we would achieve this:\n",
    "1. Here I have to first create a DF which has all the movies except what I already rated user id should be 0.\n",
    "2. Then predict the rating for them. \n",
    "3. And then finally choose the best 50 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71db86d1-fa10-4012-8443-ece18ca738e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "my_rated_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba3ebc05-cad6-4abd-ad4d-22953603b6ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of my rated movie IDs\n",
    "my_rated_movie_ids = [x[1] for x in my_rated_movies]\n",
    "\n",
    "# Filter out the movies I already rated.'~' sign will make sure not to include them.\n",
    "not_rated_df = movies_df.filter(~ movies_df['ID'].isin(my_rated_movie_ids))\n",
    "\n",
    "# Rename the \"ID\" column to be \"movieId\", and add a column with my_user_id as \"userId\".\n",
    "my_unrated_movies_df = not_rated_df.withColumnRenamed('ID','movieId').withColumn('userId',F.lit(0))\n",
    "\n",
    "# Use my_rating_model to predict ratings for the movies that I did not manually rate.\n",
    "raw_predicted_ratings_df = my_ratings_model.transform(my_unrated_movies_df)\n",
    "\n",
    "predicted_ratings_df = raw_predicted_ratings_df.filter(raw_predicted_ratings_df['prediction'] != float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89ce3c8d-91e8-4efa-af0e-404e37ce141c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#some sample ratings\n",
    "predicted_ratings_df.show(4,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b5b7161-3a79-49ed-b5d3-f71c158f62f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "One Last trick I don't want to see a movie which is very new I mean it should atleast have some reviews say 400 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "460c46ba-5ae5-44a4-8fd5-7852b0d90e98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predicted_with_counts_df = predicted_ratings_df.join(movie_names_with_avg_ratings_df,predicted_ratings_df.movieId== movie_names_with_avg_ratings_df.movieId)\n",
    "predicted_highest_rated_movies_df = predicted_with_counts_df.filter(predicted_with_counts_df['count'] > 400).sort('prediction',ascending = False)\n",
    "\n",
    "print ('My 50 highest rated movies as predicted (for movies with more than 400 reviews):')\n",
    "display(predicted_highest_rated_movies_df.show(50,truncate = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3eb513a8-3729-4bd5-b989-a2d761fdfc57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3736276534442998,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Movies Recommendation",
   "widgets": {}
  },
  "name": "Movie_Lens_20M",
  "notebookId": 3123150065672593
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
